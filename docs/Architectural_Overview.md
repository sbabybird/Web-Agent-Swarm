# Architectural Overview: Web Agent Swarm

## 1. Core Philosophy: A Multi-Capability Agent Platform

This project has evolved from a simple web automation tool into a sophisticated, multi-capability agent platform. The core principle is no longer about executing a fixed set of commands, but about empowering a hierarchy of Large Language Models (LLMs) to understand diverse user goals and generate executable code to achieve them.

The system is built on a **Manager/Expert** model:

1.  **Manager Agent (The Dispatcher):** This top-level agent analyzes the user's natural language goal to determine its fundamental *intent*. It does not concern itself with *how* to achieve the goal, but rather *what kind* of task it is.

2.  **Expert Agents (The Specialists):** These are specialized agents, each trained (via a detailed prompt) on a specific domain. They receive the user's goal from the Manager and are responsible for generating the high-quality, executable code required to complete the task.

3.  **Executor Services (The Runtimes):** These are secure environments responsible for running the code generated by the experts.

This decoupled architecture is highly extensible, allowing for the easy addition of new "expert" agents and "executor" services in the future.

---

## 2. System Components

### 2.1. Frontend (`React + TypeScript + Vite`)

The frontend serves as the primary user interface and the orchestration hub.

*   **`App.tsx`**: The main component that manages state, user input, and the overall workflow.
*   **`components/DrawingCanvas.tsx`**: A specialized React component that houses an HTML `<canvas>`. It is responsible for safely executing JavaScript code generated by the *Drawing Expert* using the Canvas 2D API.
*   **`prompts/`**: This directory externalizes all LLM prompts from the application logic, making them easy to maintain and modify. It contains:
    *   `manager_prompt.txt`: Instructs the Manager Agent on how to classify tasks.
    *   `browser_prompt.txt`: Instructs the Browser Expert on how to generate Playwright code.
    *   `drawing_prompt.txt`: Instructs the Drawing Expert on how to generate Canvas API code.

### 2.2. Backend (`Node.js + Express`)

The backend acts as a secure gateway for capabilities that cannot be run directly in the browser.

*   **`server.js`**: The main Express server.
*   **`/run-llm`**: A proxy endpoint that securely forwards prompts to the specified LLM service (e.g., Ollama), shielding the frontend from needing direct access.
*   **`/execute-code`**: The executor service for browser automation. It uses Node.js's built-in `vm` module to create a **secure, isolated sandbox**. This sandbox receives Playwright code from the frontend and executes it, ensuring the code can only interact with the provided `page` object and nothing else on the server.
*   **`/log-error`**: A utility endpoint for the frontend to report JavaScript execution errors, aiding in debugging LLM-generated code.

### 2.3. Deployment (`Docker + Docker Compose`)

The entire system is containerized for portability and ease of setup.

*   **`docker-compose.yml`**: Orchestrates the `frontend` and `backend` services.
*   **`Dockerfile`**: Separate Dockerfiles for each service define their respective environments.
*   **`.dockerignore`**: Crucially, these files prevent the local `node_modules` directories from being copied into the Docker image during the build process, avoiding common permission and path issues, especially on Windows.
*   **Volume Strategy**: The configuration uses a hybrid approach to balance performance and developer experience. Source code is mounted directly for live-reloading, while `node_modules` are handled by high-performance named volumes within the Docker engine. The local `node_modules` (installed manually by the developer) are used only for IDE intellisense.

---

## 3. Workflow & Data Flow

Here is the step-by-step data flow for a typical user request:

1.  **User Input**: The user types a goal (e.g., "Draw a clock") into the UI and clicks "Execute Goal".

2.  **Manager Invocation**: `App.tsx` populates the `manager_prompt.txt` template with the user's goal and sends it to the `/run-llm` endpoint.

3.  **Task Classification**: The LLM, acting as the Manager, analyzes the goal and returns a JSON object classifying the task, e.g., `{ "taskType": "drawing" }`.

4.  **Expert Invocation**: `App.tsx` receives this classification. It then selects the appropriate expert prompt (e.g., `drawing_prompt.txt`), populates it with the user's goal, and sends it back to the `/run-llm` endpoint.

5.  **Code Generation**: The LLM, now acting as an Expert (e.g., the Drawing Expert), generates the executable JavaScript code required to fulfill the goal.

6.  **Execution**: `App.tsx` receives the generated code.
    *   If `taskType` is `drawing`, the code is passed as a prop to the `DrawingCanvas.tsx` component, which executes it safely on the frontend.
    *   If `taskType` is `browser_automation`, the code is sent to the `/execute-code` endpoint on the backend, which executes it in a secure `vm` sandbox.

7.  **Feedback**: The results and logs from the execution are displayed in the UI, providing a complete feedback loop to the user.
