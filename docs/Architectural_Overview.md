# 架构概览: Web Agent Swarm

## 1. 核心理念: 一个多能力智能体平台

本项目已从一个简单的网页自动化工具，演进为一个复杂精密的、多能力的智能体平台。其核心原则不再是执行一组固定的命令，而是赋能一个由大型语言模型（LLM）构成的层级体系，使其能够理解多样化的用户目标，并生成可执行的代码来达成这些目标。

系统构建于一个 **“管理者/专家” (Manager/Expert)** 模型之上：

1.  **管理者智能体 (任务调度总管):** 这个顶层智能体负责分析用户的自然语言目标，以判断其根本*意图*。它不关心*如何*实现目标，而是关心这是*何种类型*的任务。

2.  **专家智能体 (领域专家):** 这些是专门化的智能体，每一个都通过一个详细的提示词（Prompt），在特定的领域内受过“训练”。它们从管理者那里接收用户目标，并负责生成完成任务所需的高质量、可执行的代码。

3.  **执行器服务 (运行时环境):** 这些是安全的环境，负责运行由专家们生成的代码。

这种解耦的架构具有高度的可扩展性，允许未来轻松地加入新的“专家”智能体和“执行器”服务。

---

## 2. 系统组件

### 2.1. 前端 (`React + TypeScript + Vite`)

前端是主要的用户界面和任务编排中心。

*   **`App.tsx`**: 管理状态、用户输入和整体工作流的核心组件。
*   **`components/DrawingCanvas.tsx`**: 一个专门的React组件，内含一个HTML `<canvas>`。它负责安全地执行由*绘画专家*生成的、使用Canvas 2D API的JavaScript代码。
*   **`prompts/`**: 该目录将所有LLM提示词从应用逻辑中分离出来，使它们易于维护和修改。它包含：
    *   `manager_prompt.txt`: 指导管理者智能体如何对任务进行分类。
    *   `browser_prompt.txt`: 指导浏览器专家如何生成Playwright代码。
    *   `drawing_prompt.txt`: 指导绘画专家如何生成Canvas API代码。

### 2.2. 后端 (`Node.js + Express`)

后端充当一个安全网关，处理那些无法直接在浏览器中运行的能力。

*   **`server.js`**: Express主服务器。
*   **`/run-llm`**: 一个代理端点，它安全地将提示词转发到指定的LLM服务（如Ollama），从而避免了前端需要直接访问LLM服务。
*   **`/execute-code`**: 用于浏览器自动化的执行器服务。它使用Node.js内置的`vm`模块来创建一个**安全的、隔离的沙箱**。这个沙箱从前端接收Playwright代码并执行，确保代码只能与我们明确提供的`page`对象交互，而不能触及服务器上的任何其他东西。
*   **`/log-error`**: 一个工具性端点，供前端上报JavaScript执行错误，以辅助调试由LLM生成的代码。

### 2.3. 部署 (`Docker + Docker Compose`)

整个系统被容器化，以实现可移植性和便捷的安装。

*   **`docker-compose.yml`**: 编排`frontend`和`backend`服务。
*   **`Dockerfile`**: 每个服务都有独立的Dockerfile，定义了其各自的环境。
*   **`.dockerignore`**: 这些至关重要的文件，可以防止本地的`node_modules`目录在镜像构建过程中被复制进去，从而避免了常见的权限和路径问题（尤其是在Windows上）。
*   **卷策略 (Volume Strategy)**: 配置采用了一种混合方法，以平衡性能和开发者体验。源代码被直接挂载以实现实时重载，而`node_modules`则由Docker引擎内的高性能命名卷来处理。开发者在本地手动安装的`node_modules`，仅用于IDE的智能提示。

---

## 3. 工作流与数据流

对于一个典型的用户请求，其端到端的数据流如下：

1.  **用户输入**: 用户在UI中输入一个目标（例如：“画一个时钟”）并点击“执行”。

2.  **管理者调用**: `App.tsx` 使用用户目标填充`manager_prompt.txt`模板，并将其发送到`/run-llm`端点。

3.  **任务分类**: LLM（扮演管理者角色）分析目标，并返回一个JSON对象来对任务进行分类，例如：`{ "taskType": "drawing" }`。

4.  **专家调用**: `App.tsx`接收到这个分类结果。然后，它会选择相应的专家提示词（例如`drawing_prompt.txt`），用用户目标填充它，并再次发送到`/run-llm`端点。

5.  **代码生成**: LLM（现在扮演专家角色，如绘画专家）生成完成任务所需的可执行JavaScript代码。

6.  **执行**: `App.tsx`接收到生成的代码。
    *   如果`taskType`是`drawing`，代码会被作为prop传递给`DrawingCanvas.tsx`组件，并在前端安全地执行。
    *   如果`taskType`是`browser_automation`，代码会被发送到后端的`/execute-code`端点，并在一个安全的`vm`沙箱中执行。

7.  **反馈**: 执行过程中的结果和日志，都会被显示在UI中，为用户提供一个完整的反馈闭环。